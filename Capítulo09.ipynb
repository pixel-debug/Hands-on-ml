{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Capítulo09.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBR4eziG5Cq59dHbP9xRRe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pixel-debug/Hands-on-ml/blob/master/Cap%C3%ADtulo09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pH99sWO8RA9"
      },
      "source": [
        "# Capítulo 09\n",
        "\n",
        "Em Pleno Funcionamento com o TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYHM4axXGXkC"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf2Uc-JEGXkD"
      },
      "source": [
        "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3QDTtVMGXkD",
        "outputId": "c3a5be1e-cbb2-40f3-8692-43577f784afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 1.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"tensorflow\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEtD2BOdGXkF"
      },
      "source": [
        "## Creating and running a graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWU_9fsWGXkG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "x = tf.Variable(3, name=\"x\")\n",
        "y = tf.Variable(4, name=\"y\")\n",
        "f = x*x*y + y + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMOtqawmGXkH",
        "outputId": "a8b488e0-01fe-4914-fb4a-bd4f6c1091df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua8wlD-SGXkI",
        "outputId": "3c21ec31-929f-482b-97eb-9430ab7ce788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42\n"
          ]
        }
      ],
      "source": [
        "sess = tf.Session()\n",
        "sess.run(x.initializer)\n",
        "sess.run(y.initializer)\n",
        "result = sess.run(f)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUFCP1roGXkJ"
      },
      "outputs": [],
      "source": [
        "sess.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxBQDuLlGXkJ"
      },
      "outputs": [],
      "source": [
        "with tf.Session() as sess:\n",
        "    x.initializer.run()\n",
        "    y.initializer.run()\n",
        "    result = f.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWNTxdZRGXkK",
        "outputId": "357fb730-9b0f-44eb-f98d-dbab3019e2a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU_NIyAwGXkK"
      },
      "outputs": [],
      "source": [
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    result = f.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i9Llt6vGXkM",
        "outputId": "e6958b45-b7f8-45fa-b7b1-52a1c720868c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDze5T1MGXkM"
      },
      "outputs": [],
      "source": [
        "init = tf.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GotG5KfjGXkN",
        "outputId": "96f137dd-262d-4afd-8247-29576d17195d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42\n"
          ]
        }
      ],
      "source": [
        "sess = tf.InteractiveSession()\n",
        "init.run()\n",
        "result = f.eval()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9QSwdWiGXkN"
      },
      "outputs": [],
      "source": [
        "sess.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCK6NnZAGXkO",
        "outputId": "410ad675-e300-40f1-dd5f-3ce130de33fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5srGQWnxGXkO"
      },
      "source": [
        "## Managing graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1GtWLxfGXkO",
        "outputId": "6f4fb0d9-9f9c-4c2c-858f-e4a983e88b84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reset_graph()\n",
        "\n",
        "x1 = tf.Variable(1)\n",
        "x1.graph is tf.get_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qDLjK1EGXkP",
        "outputId": "51032e91-403d-4128-9d2a-a90493e5cfaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    x2 = tf.Variable(2)\n",
        "\n",
        "x2.graph is graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfJRg6oSGXkS",
        "outputId": "ed9ab3ac-4229-4023-91de-e61111339464",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x2.graph is tf.get_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrbB6qX_GXkT",
        "outputId": "2830a04f-88e8-4fc2-e751-c635524ab1e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ]
        }
      ],
      "source": [
        "w = tf.constant(3)\n",
        "x = w + 2\n",
        "y = x + 5\n",
        "z = x * 3\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(y.eval())  # 10\n",
        "    print(z.eval())  # 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfQ4AO09GXkT",
        "outputId": "9c07c4d6-ea96-4d90-cf0b-13fddc64bc2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ]
        }
      ],
      "source": [
        "with tf.Session() as sess:\n",
        "    y_val, z_val = sess.run([y, z])\n",
        "    print(y_val)  # 10\n",
        "    print(z_val)  # 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-2Desr5GXkT"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8-2sPSgGXkU"
      },
      "source": [
        "### Using the Normal Equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB6_z6OPGXkU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
        "\n",
        "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "XT = tf.transpose(X)\n",
        "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    theta_value = theta.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu5HyYtpGXkU",
        "outputId": "2843db92-ce1a-4c22-f835-c0e97f5ce3fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-3.7185181e+01],\n",
              "       [ 4.3633747e-01],\n",
              "       [ 9.3952334e-03],\n",
              "       [-1.0711310e-01],\n",
              "       [ 6.4479220e-01],\n",
              "       [-4.0338000e-06],\n",
              "       [-3.7813708e-03],\n",
              "       [-4.2348403e-01],\n",
              "       [-4.3721911e-01]], dtype=float32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "theta_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4YzYzYeGXkU"
      },
      "source": [
        "Compare with pure NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l02_FE7EGXkV",
        "outputId": "df6d2c44-c2f8-45cb-a619-c10a9dfeea3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-3.69419202e+01]\n",
            " [ 4.36693293e-01]\n",
            " [ 9.43577803e-03]\n",
            " [-1.07322041e-01]\n",
            " [ 6.45065694e-01]\n",
            " [-3.97638942e-06]\n",
            " [-3.78654265e-03]\n",
            " [-4.21314378e-01]\n",
            " [-4.34513755e-01]]\n"
          ]
        }
      ],
      "source": [
        "X = housing_data_plus_bias\n",
        "y = housing.target.reshape(-1, 1)\n",
        "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
        "\n",
        "print(theta_numpy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoYR2ToLGXkV"
      },
      "source": [
        "Compare with Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVpX_x0dGXkV",
        "outputId": "fd9d8060-0c1c-4610-ff49-a2f0828ebfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-3.69419202e+01]\n",
            " [ 4.36693293e-01]\n",
            " [ 9.43577803e-03]\n",
            " [-1.07322041e-01]\n",
            " [ 6.45065694e-01]\n",
            " [-3.97638942e-06]\n",
            " [-3.78654265e-03]\n",
            " [-4.21314378e-01]\n",
            " [-4.34513755e-01]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
        "\n",
        "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2wDDV4vGXkV"
      },
      "source": [
        "#### Using Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkwoLskUGXkV"
      },
      "source": [
        "Gradient Descent requires scaling the feature vectors first. We could do this using TF, but let's just use Scikit-Learn for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-SYjxgEGXkW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_housing_data = scaler.fit_transform(housing.data)\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FSCcu0XGXkW",
        "outputId": "d8d06ba8-a674-4d1a-8d11-adbc7f9fdcb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1.00000000e+00  6.60969987e-17  5.50808322e-18  6.60969987e-17\n",
            " -1.06030602e-16 -1.10161664e-17  3.44255201e-18 -1.07958431e-15\n",
            " -8.52651283e-15]\n",
            "[ 0.38915536  0.36424355  0.5116157  ... -0.06612179 -0.06360587\n",
            "  0.01359031]\n",
            "0.11111111111111005\n",
            "(20640, 9)\n"
          ]
        }
      ],
      "source": [
        "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
        "print(scaled_housing_data_plus_bias.mean(axis=1))\n",
        "print(scaled_housing_data_plus_bias.mean())\n",
        "print(scaled_housing_data_plus_bias.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtB3G0FqGXkW"
      },
      "source": [
        "#### Manually computing the gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU8j4q_KGXkW",
        "outputId": "2f2fa5ea-33d9-470e-f31e-07c111c62d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 9.161542\n",
            "Epoch 100 MSE = 0.7145004\n",
            "Epoch 200 MSE = 0.56670487\n",
            "Epoch 300 MSE = 0.5555718\n",
            "Epoch 400 MSE = 0.5488112\n",
            "Epoch 500 MSE = 0.5436363\n",
            "Epoch 600 MSE = 0.5396291\n",
            "Epoch 700 MSE = 0.5365092\n",
            "Epoch 800 MSE = 0.53406775\n",
            "Epoch 900 MSE = 0.5321473\n"
          ]
        }
      ],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
        "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06EEm1SLGXkX",
        "outputId": "fef70bb8-7ec4-4e2f-a17d-710fc9d7f2fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.0685523 ],\n",
              "       [ 0.8874027 ],\n",
              "       [ 0.14401656],\n",
              "       [-0.34770882],\n",
              "       [ 0.36178368],\n",
              "       [ 0.00393811],\n",
              "       [-0.04269556],\n",
              "       [-0.6614529 ],\n",
              "       [-0.6375279 ]], dtype=float32)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1iVCnM6GXkX"
      },
      "source": [
        "#### Using autodiff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BYTybGoGXkY"
      },
      "source": [
        "Same as above except for the `gradients = ...` line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6Yjjc0aGXkY"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpOXjGm0GXkY"
      },
      "outputs": [],
      "source": [
        "gradients = tf.gradients(mse, [theta])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHA4uWGOGXkY",
        "outputId": "80ff597d-da0e-4235-8900-3fd113dc67da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 9.161542\n",
            "Epoch 100 MSE = 0.71450037\n",
            "Epoch 200 MSE = 0.56670487\n",
            "Epoch 300 MSE = 0.5555718\n",
            "Epoch 400 MSE = 0.54881126\n",
            "Epoch 500 MSE = 0.5436363\n",
            "Epoch 600 MSE = 0.53962916\n",
            "Epoch 700 MSE = 0.5365092\n",
            "Epoch 800 MSE = 0.53406775\n",
            "Epoch 900 MSE = 0.5321473\n",
            "Best theta:\n",
            "[[ 2.0685523 ]\n",
            " [ 0.8874027 ]\n",
            " [ 0.14401656]\n",
            " [-0.3477088 ]\n",
            " [ 0.36178365]\n",
            " [ 0.00393811]\n",
            " [-0.04269556]\n",
            " [-0.66145283]\n",
            " [-0.6375278 ]]\n"
          ]
        }
      ],
      "source": [
        "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "\n",
        "print(\"Best theta:\")\n",
        "print(best_theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K2yRhohGXkY"
      },
      "source": [
        "How could you find the partial derivatives of the following function with regards to `a` and `b`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv7Om8IpGXkY"
      },
      "outputs": [],
      "source": [
        "def my_func(a, b):\n",
        "    z = 0\n",
        "    for i in range(100):\n",
        "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqK-TUwUGXkZ",
        "outputId": "67b21b4a-7d01-4ed1-bdc7-c8320b0ef61e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.21253923284754914"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_func(0.2, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4j2mBYCGXkZ"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "a = tf.Variable(0.2, name=\"a\")\n",
        "b = tf.Variable(0.3, name=\"b\")\n",
        "z = tf.constant(0.0, name=\"z0\")\n",
        "for i in range(100):\n",
        "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
        "\n",
        "grads = tf.gradients(z, [a, b])\n",
        "init = tf.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7yX58k8GXkZ"
      },
      "source": [
        "Let's compute the function at $a=0.2$ and $b=0.3$, and the partial derivatives at that point with regards to $a$ and with regards to $b$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUcRIeM9GXkZ",
        "outputId": "e444c9a8-f031-4230-8957-8f9a011d17e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.21253741\n",
            "[-1.1388495, 0.19671397]\n"
          ]
        }
      ],
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    print(z.eval())\n",
        "    print(sess.run(grads))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7L20ogGGXkZ"
      },
      "source": [
        "#### Using a `GradientDescentOptimizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "U_zTBioPGXka",
        "outputId": "dcb7de75-4852-42d9-f2d8-3313f9492ad9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dc9d93731dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'reset_graph' is not defined"
          ]
        }
      ],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR0FGL8CGXka"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxmEjSOHGXka"
      },
      "outputs": [],
      "source": [
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "\n",
        "print(\"Best theta:\")\n",
        "print(best_theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-tI2RkYGXka"
      },
      "source": [
        "#### Using a momentum optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4ysL1-vGXka"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s_PbGv8GXkb"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
        "                                       momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUXL9yjIGXkb"
      },
      "outputs": [],
      "source": [
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrZ93772GXkb",
        "outputId": "161115f4-1c2d-472a-faed-bf620edb3aa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best theta:\n",
            "[[ 2.068558  ]\n",
            " [ 0.82962847]\n",
            " [ 0.11875335]\n",
            " [-0.26554456]\n",
            " [ 0.3057109 ]\n",
            " [-0.00450249]\n",
            " [-0.03932662]\n",
            " [-0.8998645 ]\n",
            " [-0.8705207 ]]\n"
          ]
        }
      ],
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "\n",
        "print(\"Best theta:\")\n",
        "print(best_theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMoSsx2XGXkb"
      },
      "source": [
        "## Feeding data to the training algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSJlyS0gGXkb"
      },
      "source": [
        "### Placeholder nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qovOjxdCGXkb",
        "outputId": "e7e90fa1-0b91-4918-a0df-d1c687a3c47b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6. 7. 8.]]\n"
          ]
        }
      ],
      "source": [
        "reset_graph()\n",
        "\n",
        "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
        "B = A + 5\n",
        "with tf.Session() as sess:\n",
        "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
        "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
        "\n",
        "print(B_val_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4LDVE_qGXkc",
        "outputId": "17155df5-5542-42bc-abf2-9b6574307d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 9. 10. 11.]\n",
            " [12. 13. 14.]]\n"
          ]
        }
      ],
      "source": [
        "print(B_val_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr6PZmQwGXkc"
      },
      "source": [
        "### Mini-batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NumMr0opGXkc"
      },
      "outputs": [],
      "source": [
        "n_epochs = 1000\n",
        "learning_rate = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RypN6BqLGXkd"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFnio7LbGXkd"
      },
      "outputs": [],
      "source": [
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEA52-AkGXkd"
      },
      "outputs": [],
      "source": [
        "n_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqzCtxnAGXkd"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "n_batches = int(np.ceil(m / batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiAq1g4AGXkd"
      },
      "outputs": [],
      "source": [
        "def fetch_batch(epoch, batch_index, batch_size):\n",
        "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
        "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
        "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
        "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
        "    return X_batch, y_batch\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "    best_theta = theta.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UN0ANY2GXkd",
        "outputId": "025d06e8-9c15-4b1c-c627-3b092765592e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.0703337 ],\n",
              "       [ 0.8637145 ],\n",
              "       [ 0.12255152],\n",
              "       [-0.31211877],\n",
              "       [ 0.38510376],\n",
              "       [ 0.00434168],\n",
              "       [-0.0123295 ],\n",
              "       [-0.83376896],\n",
              "       [-0.8030471 ]], dtype=float32)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95s2h_fmGXke"
      },
      "source": [
        "## Saving and restoring a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDDy3mORGXke",
        "outputId": "7cdc8c98-b079-4f00-f701-bb8aeee11b58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 9.161542\n",
            "Epoch 100 MSE = 0.7145004\n",
            "Epoch 200 MSE = 0.56670487\n",
            "Epoch 300 MSE = 0.5555718\n",
            "Epoch 400 MSE = 0.54881126\n",
            "Epoch 500 MSE = 0.5436363\n",
            "Epoch 600 MSE = 0.53962916\n",
            "Epoch 700 MSE = 0.5365092\n",
            "Epoch 800 MSE = 0.53406775\n",
            "Epoch 900 MSE = 0.5321473\n"
          ]
        }
      ],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000                                                                       # not shown in the book\n",
        "learning_rate = 0.01                                                                  # not shown\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")            # not shown\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")            # not shown\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")                                      # not shown\n",
        "error = y_pred - y                                                                    # not shown\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")                                    # not shown\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)            # not shown\n",
        "training_op = optimizer.minimize(mse)                                                 # not shown\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())                                # not shown\n",
        "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HybziXuLGXke",
        "outputId": "3afb2cde-397e-41db-da58-71f48ab6f6ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.0685523 ],\n",
              "       [ 0.8874027 ],\n",
              "       [ 0.14401656],\n",
              "       [-0.3477088 ],\n",
              "       [ 0.36178365],\n",
              "       [ 0.00393811],\n",
              "       [-0.04269556],\n",
              "       [-0.66145283],\n",
              "       [-0.6375278 ]], dtype=float32)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs2wN3jXGXkf",
        "outputId": "cf03638d-18c3-4287-8d72-4394bed380b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
          ]
        }
      ],
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
        "    best_theta_restored = theta.eval() # not shown in the book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzWzjigLGXkf",
        "outputId": "122d3fa9-a34e-4be8-e850-fd1430215b4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.allclose(best_theta, best_theta_restored)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAAwfA9eGXkf"
      },
      "source": [
        "If you want to have a saver that loads and restores `theta` with a different name, such as `\"weights\"`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tPXuePlGXkf"
      },
      "outputs": [],
      "source": [
        "saver = tf.train.Saver({\"weights\": theta})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fibbUny5GXkg"
      },
      "source": [
        "By default the saver also saves the graph structure itself in a second file with the extension `.meta`. You can use the function `tf.train.import_meta_graph()` to restore the graph structure. This function loads the graph into the default graph and returns a `Saver` that can then be used to restore the graph state (i.e., the variable values):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x10MEWsGXkg",
        "outputId": "544d5660-2237-4648-e8f8-047e2fd0a71d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
          ]
        }
      ],
      "source": [
        "reset_graph()\n",
        "# notice that we start with an empty graph.\n",
        "\n",
        "saver = tf.train.import_meta_graph(\"/tmp/my_model_final.ckpt.meta\")  # this loads the graph structure\n",
        "theta = tf.get_default_graph().get_tensor_by_name(\"theta:0\") # not shown in the book\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")  # this restores the graph's state\n",
        "    best_theta_restored = theta.eval() # not shown in the book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpd1yOBMGXkg",
        "outputId": "33425999-a79e-4f4f-f9c5-cbc9b285cd63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.allclose(best_theta, best_theta_restored)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dldTSiqkGXkg"
      },
      "source": [
        "This means that you can import a pretrained model without having to have the corresponding Python code to build the graph. This is very handy when you keep tweaking and saving your model: you can load a previously saved model without having to search for the version of the code that built it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_jk8ktYGXkh"
      },
      "source": [
        "## Visualizing the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-343aJRGXkh"
      },
      "source": [
        "TensorBoard is a great tool to visualize TensorFlow graphs, training curves, and much more. Our TensorFlow code will write various files in a log directory, and the TensorBoard server will regularly read these files and produce nice interactive visualizations. It can plot graphs, learning curves (i.e., how the loss evaluated on the training set or test set evolves as a function of the epoch number), profiling data to identify performance bottlenecks, and more. In short, it helps keep track of everything. Here's the overall picture:\n",
        "\n",
        "`TensorFlow writes logs to ===> log directory ===> TensorBoard reads data and displays visualizations`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpSz9ruDGXkh"
      },
      "source": [
        "If we want to visualize different graphs, or learning curves for different training runs, we don't want the log files to get all mixed up. So we will need one log subdirectory per graph, or per run. Let's use a root log directory that we will call `tf_logs`, and a sub-directory that we will call `run-` followed by the current timestamp (you can use any other name you prefer in your own code):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nShM5jgGXkh"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "root_logdir = \"tf_logs\"\n",
        "logdir = \"{}/run-{}/\".format(root_logdir, now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WTGntudGXkh",
        "outputId": "b6d135fa-b684-49b0-fa35-37d91b5483b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tf_logs/run-20210325095200/'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logdir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogql7XMuGXkh"
      },
      "source": [
        "In fact, let's create a function that will generate such a subdirectory path every time we need one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jts5tAB7GXkh"
      },
      "outputs": [],
      "source": [
        "def make_log_subdir(run_id=None):\n",
        "    if run_id is None:\n",
        "        run_id = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "    return \"{}/run-{}/\".format(root_logdir, run_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8kaQ-RMGXki"
      },
      "source": [
        "Now let's save the default graph to our log subdirectory using `tf.summary.FileWriter()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-8iLEdjGXki"
      },
      "outputs": [],
      "source": [
        "file_writer = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZDBU-rxGXki"
      },
      "source": [
        "Now the root log directory contains one subdirectory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN4pSJ_qGXki",
        "outputId": "e6c19c16-c5fa-4cc9-bf1c-a3700348b97b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['run-20210325095200']"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(root_logdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjShr7Q2GXki"
      },
      "source": [
        "And this subdirectory contains one log file (called a \"TF events\" file) for the graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcV-x_JDGXki",
        "outputId": "d11a062e-67af-4f2e-fbb8-943ada5e2d03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['events.out.tfevents.1616665937.kiwimac']"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(logdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9iwoDM7GXkj"
      },
      "source": [
        "However, the actual graph data may still be in the OS's file cache, so we need to `flush()` or `close()` the `FileWriter` to be sure that it's well written to disk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntAs51_wGXkj"
      },
      "outputs": [],
      "source": [
        "file_writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt2CMqmOGXkj"
      },
      "source": [
        "Okay, now let's start TensorBoard! It runs as a web server in a separate process, so we first need to start it. One way to do that is to run the `tensorboard` command in a terminal window. Another is to use the `%tensorboard` Jupyter extension, which takes care of starting TensorBoard, and it allows us to view TensorBoard's user interface directly within Jupyter. Let's load this extension now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvm4AUiTGXkj",
        "outputId": "e395002d-e30b-4682-ff6b-c53bd000bc1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln_VosSeGXkj"
      },
      "source": [
        "Next, let's use the `%tensorboard` extension to start the TensorBoard server. We need to point it to the root log directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9AQJYMWGXkj",
        "outputId": "122ac404-79fe-49e8-ba09-ae3417e637ae",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-9bb87ff5937c48c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-9bb87ff5937c48c\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir {root_logdir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgD8LuE3GXkk"
      },
      "source": [
        "Great! We can now visualize graphs. :)\n",
        "\n",
        "In fact, let's make this easy by creating a `save_graph()` function that will automatically create a new log subdir and save the given graph (by default `tf.get_default_graph()`) to this directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWa0JN6zGXkk"
      },
      "outputs": [],
      "source": [
        "def save_graph(graph=None, run_id=None):\n",
        "    if graph is None:\n",
        "        graph = tf.get_default_graph()\n",
        "    logdir = make_log_subdir(run_id)\n",
        "    file_writer = tf.summary.FileWriter(logdir, graph=graph)\n",
        "    file_writer.close()\n",
        "    return logdir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juyz-OPSGXkk"
      },
      "source": [
        "Let's see if it works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRWGwatkGXkk",
        "outputId": "11ffe4ff-21d6-492f-c3f7-0aeb505c1a01",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tf_logs/run-20210325095244/'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G7sPeW_GXkk"
      },
      "source": [
        "Now let's look at TensorBoard again. Note that this will reuse the existing TensorBoard server since we're reusing the same root log directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyG0XXApGXkl",
        "outputId": "3f56b7f4-cc85-4c3a-a2ca-6f5a10a32ef2",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 43590), started 0:00:45 ago. (Use '!kill 43590' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-6698e989b3fca11b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-6698e989b3fca11b\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir {root_logdir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAr2XK-IGXkl"
      },
      "source": [
        "Notice that you can switch between runs by picking the log subdirectory you want from the \"Run\" dropdown list (at the top left)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-ogBWgpGXkl"
      },
      "source": [
        "## Visualizing Learning Curves\n",
        "\n",
        "Now let's see how to visualize learning curves:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4XTkREZGXkl"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VECPiUrtGXkl"
      },
      "outputs": [],
      "source": [
        "logdir = make_log_subdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX8ZkF7CGXkm"
      },
      "outputs": [],
      "source": [
        "mse_summary = tf.summary.scalar('MSE', mse)\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8G-SCJyGXkm"
      },
      "outputs": [],
      "source": [
        "n_epochs = 10\n",
        "batch_size = 100\n",
        "n_batches = int(np.ceil(m / batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhTdnv5fGXkm"
      },
      "outputs": [],
      "source": [
        "with tf.Session() as sess:                                                        # not shown in the book\n",
        "    sess.run(init)                                                                # not shown\n",
        "\n",
        "    for epoch in range(n_epochs):                                                 # not shown\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            if batch_index % 10 == 0:\n",
        "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "                step = epoch * n_batches + batch_index\n",
        "                file_writer.add_summary(summary_str, step)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "    best_theta = theta.eval()                                                     # not shown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnItkwYLGXkm"
      },
      "outputs": [],
      "source": [
        "file_writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYpEb_7vGXkm",
        "outputId": "6941c3ce-8186-4f0b-fed1-684b44b6f634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.07033372],\n",
              "       [ 0.86371452],\n",
              "       [ 0.12255151],\n",
              "       [-0.31211874],\n",
              "       [ 0.38510373],\n",
              "       [ 0.00434168],\n",
              "       [-0.01232954],\n",
              "       [-0.83376896],\n",
              "       [-0.80304712]], dtype=float32)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmtKPcMiGXkm"
      },
      "source": [
        "Now let's look at TensorBoard. Try going to the SCALARS tab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shAwomVwGXkn",
        "outputId": "d23d46c6-cecd-4d31-fff0-cc5b0298a659"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 43590), started 0:02:08 ago. (Use '!kill 43590' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-6549bb5697dded37\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-6549bb5697dded37\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir {root_logdir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL-SdE64GXkn"
      },
      "source": [
        "## Name scopes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV9EGM5GGXkn"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsPpsOfVGXkn"
      },
      "outputs": [],
      "source": [
        "with tf.name_scope(\"loss\") as scope:\n",
        "    error = y_pred - y\n",
        "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OucN0UlIGXkn"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "mse_summary = tf.summary.scalar('MSE', mse)\n",
        "\n",
        "logdir = make_log_subdir()\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX1sxBAwGXko",
        "outputId": "e9bf9af9-3ede-4cab-b53f-db78a670b73f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best theta:\n",
            "[[ 2.07033372]\n",
            " [ 0.86371452]\n",
            " [ 0.12255151]\n",
            " [-0.31211874]\n",
            " [ 0.38510373]\n",
            " [ 0.00434168]\n",
            " [-0.01232954]\n",
            " [-0.83376896]\n",
            " [-0.80304712]]\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "batch_size = 100\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            if batch_index % 10 == 0:\n",
        "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "                step = epoch * n_batches + batch_index\n",
        "                file_writer.add_summary(summary_str, step)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "    best_theta = theta.eval()\n",
        "\n",
        "file_writer.flush()\n",
        "file_writer.close()\n",
        "print(\"Best theta:\")\n",
        "print(best_theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5M35AXh-GXko",
        "outputId": "c84aad72-cf44-4109-8c1d-56215f023767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss/sub\n"
          ]
        }
      ],
      "source": [
        "print(error.op.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GvjjHyWGXko",
        "outputId": "989dc87a-b4d3-4ca4-e1ab-7d767502bbbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss/mse\n"
          ]
        }
      ],
      "source": [
        "print(mse.op.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC-Q-7pGGXkp",
        "outputId": "e70c014a-ba07-402c-abb2-771971a5fd2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a\n",
            "a_1\n",
            "param/a\n",
            "param_1/a\n"
          ]
        }
      ],
      "source": [
        "reset_graph()\n",
        "\n",
        "a1 = tf.Variable(0, name=\"a\")      # name == \"a\"\n",
        "a2 = tf.Variable(0, name=\"a\")      # name == \"a_1\"\n",
        "\n",
        "with tf.name_scope(\"param\"):       # name == \"param\"\n",
        "    a3 = tf.Variable(0, name=\"a\")  # name == \"param/a\"\n",
        "\n",
        "with tf.name_scope(\"param\"):       # name == \"param_1\"\n",
        "    a4 = tf.Variable(0, name=\"a\")  # name == \"param_1/a\"\n",
        "\n",
        "for node in (a1, a2, a3, a4):\n",
        "    print(node.op.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqilOz40GXkp"
      },
      "source": [
        "## Modularity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOUtIml9GXkp"
      },
      "source": [
        "An ugly flat code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTVg_HIjGXkq"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
        "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
        "b1 = tf.Variable(0.0, name=\"bias1\")\n",
        "b2 = tf.Variable(0.0, name=\"bias2\")\n",
        "\n",
        "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
        "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
        "\n",
        "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
        "relu2 = tf.maximum(z1, 0., name=\"relu2\")  # Oops, cut&paste error! Did you spot it?\n",
        "\n",
        "output = tf.add(relu1, relu2, name=\"output\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVKYU485GXkq"
      },
      "source": [
        "Much better, using a function to build the ReLUs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWEWzt-NGXkq"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    w_shape = (int(X.get_shape()[1]), 1)\n",
        "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
        "    b = tf.Variable(0.0, name=\"bias\")\n",
        "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
        "    return tf.maximum(z, 0., name=\"relu\")\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZTvLjj3GXkr",
        "outputId": "bbfbff08-1ace-48f1-fd1d-15d1cf92d4d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tf_logs/run-relu1/'"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_graph(run_id=\"relu1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvQnoxUsGXkr",
        "outputId": "cbdf2356-36a7-4a0f-ddb9-57dba2cac751",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 43590), started 0:04:52 ago. (Use '!kill 43590' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-88e2356596cb12df\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-88e2356596cb12df\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir {root_logdir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ9V2V1rGXkr"
      },
      "source": [
        "Even better using name scopes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iiEqKnwGXkr"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    with tf.name_scope(\"relu\"):\n",
        "        w_shape = (int(X.get_shape()[1]), 1)                          # not shown in the book\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")    # not shown\n",
        "        b = tf.Variable(0.0, name=\"bias\")                             # not shown\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                      # not shown\n",
        "        return tf.maximum(z, 0., name=\"max\")                          # not shown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maeoi3r-GXkr"
      },
      "outputs": [],
      "source": [
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5ZwsMn4GXks",
        "outputId": "67e94a20-2b67-4247-8947-e27f4a61ff56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tf_logs/run-relu2/'"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_graph(run_id=\"relu2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOm62mbdGXks",
        "outputId": "12b38236-b971-4658-ab16-0a4e81ef57f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 43590), started 0:05:43 ago. (Use '!kill 43590' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-57e36dbbc0430494\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-57e36dbbc0430494\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir {root_logdir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNm3N1XfGXks"
      },
      "source": [
        "### Sharing Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM4XgNbqGXks"
      },
      "source": [
        "Sharing a `threshold` variable the classic way, by defining it outside of the `relu()` function then passing it as a parameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTexgO9XGXkt"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X, threshold):\n",
        "    with tf.name_scope(\"relu\"):\n",
        "        w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
        "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
        "        return tf.maximum(z, threshold, name=\"max\")\n",
        "\n",
        "threshold = tf.Variable(0.0, name=\"threshold\")\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X, threshold) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhYLS09nGXku"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    with tf.name_scope(\"relu\"):\n",
        "        if not hasattr(relu, \"threshold\"):\n",
        "            relu.threshold = tf.Variable(0.0, name=\"threshold\")\n",
        "        w_shape = int(X.get_shape()[1]), 1                          # not shown in the book\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
        "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
        "        return tf.maximum(z, relu.threshold, name=\"max\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU4jfP3qGXku"
      },
      "outputs": [],
      "source": [
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L950XRLYGXku"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "with tf.variable_scope(\"relu\"):\n",
        "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
        "                                initializer=tf.constant_initializer(0.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5PQ3oAzGXku"
      },
      "outputs": [],
      "source": [
        "with tf.variable_scope(\"relu\", reuse=True):\n",
        "    threshold = tf.get_variable(\"threshold\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUMxKKASGXkv"
      },
      "outputs": [],
      "source": [
        "with tf.variable_scope(\"relu\") as scope:\n",
        "    scope.reuse_variables()\n",
        "    threshold = tf.get_variable(\"threshold\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn763BurGXkv"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    with tf.variable_scope(\"relu\", reuse=True):\n",
        "        threshold = tf.get_variable(\"threshold\")\n",
        "        w_shape = int(X.get_shape()[1]), 1                          # not shown\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
        "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
        "        return tf.maximum(z, threshold, name=\"max\")\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "with tf.variable_scope(\"relu\"):\n",
        "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
        "                                initializer=tf.constant_initializer(0.0))\n",
        "relus = [relu(X) for relu_index in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDrQOJMZGXkv",
        "outputId": "fe6a3bdc-874e-444f-b89a-ee6773061d4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tf_logs/run-relu6/'"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_graph(run_id=\"relu6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Sy0BFomGXkv",
        "outputId": "1f3f9f18-bce7-44ed-ced2-e18aeeb342e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 43590), started 0:06:21 ago. (Use '!kill 43590' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-f55ce8541b1e56b0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-f55ce8541b1e56b0\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir {root_logdir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFmrQqBwGXkv"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    with tf.variable_scope(\"relu\"):\n",
        "        threshold = tf.get_variable(\"threshold\", shape=(), initializer=tf.constant_initializer(0.0))\n",
        "        w_shape = (int(X.get_shape()[1]), 1)\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
        "        b = tf.Variable(0.0, name=\"bias\")\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
        "        return tf.maximum(z, threshold, name=\"max\")\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "with tf.variable_scope(\"\", default_name=\"\") as scope:\n",
        "    first_relu = relu(X)     # create the shared variable\n",
        "    scope.reuse_variables()  # then reuse it\n",
        "    relus = [first_relu] + [relu(X) for i in range(4)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MikHpzpuGXkw",
        "outputId": "f53478c8-605a-4753-9376-ee5d8eb3000e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tf_logs/run-relu8/'"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_graph(run_id=\"relu8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whiLP-dfGXkw",
        "outputId": "3a541a31-eb0e-4327-a108-6b52654aa7ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 43590), started 0:06:45 ago. (Use '!kill 43590' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-41cda150228bada\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-41cda150228bada\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir {root_logdir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-M6V6SIGXkw"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
        "                                initializer=tf.constant_initializer(0.0))\n",
        "    w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
        "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
        "    b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
        "    z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
        "    return tf.maximum(z, threshold, name=\"max\")\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = []\n",
        "for relu_index in range(5):\n",
        "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
        "        relus.append(relu(X))\n",
        "output = tf.add_n(relus, name=\"output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_cM85JDGXkw",
        "outputId": "17d66314-7eb1-496b-e622-21b467243df8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tf_logs/run-relu9/'"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_graph(run_id=\"relu9\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ajCM0U1GXkw",
        "outputId": "3b457dee-d353-4fcf-f9ff-320ea7700ed3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 43590), started 0:07:06 ago. (Use '!kill 43590' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-5f6a27b4563df923\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-5f6a27b4563df923\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir {root_logdir}"
      ]
    }
  ]
}